{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f1df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project root (adjust path as needed)\n",
    "project_root = os.path.abspath(\"..\")   # one folder up from current notebook\n",
    "sys.path.append(project_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a33b9",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#### Add parent folder to path so we can import resume_skill_extractor\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "\n",
    "from resume_skill_extractor.skill_extractor import extract_skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b375618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneha\\AppData\\Local\\Temp\\ipykernel_16372\\2025362762.py:5: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  OllamaEmbeddings(model=\"gemma:2b\")        ##by default it use llama2\n"
     ]
    }
   ],
   "source": [
    "from resume_skill_extractor.skill_extractor import extract_skills_cached \n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings=(\n",
    "    OllamaEmbeddings(model=\"gemma:2b\")        ##by default it use llama2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee1e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Resume skill 'Python' and JD skill 'Python': 1.0000\n",
      "Similarity between Resume skill 'Python' and JD skill 'SQL': 0.3000\n",
      "Similarity between Resume skill 'Python' and JD skill 'Deep Learning': 0.3113\n",
      "Similarity between Resume skill 'SQL' and JD skill 'Python': 0.3000\n",
      "Similarity between Resume skill 'SQL' and JD skill 'SQL': 1.0000\n",
      "Similarity between Resume skill 'SQL' and JD skill 'Deep Learning': 0.2231\n",
      "Similarity between Resume skill 'Machine Learning' and JD skill 'Python': 0.3613\n",
      "Similarity between Resume skill 'Machine Learning' and JD skill 'SQL': 0.3169\n",
      "Similarity between Resume skill 'Machine Learning' and JD skill 'Deep Learning': 0.6887\n"
     ]
    }
   ],
   "source": [
    "from resume_skill_extractor.skill_extractor import extract_skills_cached\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_skills(resume_skills, jd_skills):\n",
    "    \"\"\"\n",
    "    Embed each skill separately (one vector per skill).\n",
    "    \"\"\"\n",
    "    if not isinstance(resume_skills, list):\n",
    "        raise ValueError(\"resume_skills must be a list of strings\")\n",
    "    if not isinstance(jd_skills, list):\n",
    "        raise ValueError(\"jd_skills must be a list of strings\")\n",
    "\n",
    "    resume_vectors = embeddings.embed_documents(resume_skills)\n",
    "    jd_vectors = embeddings.embed_documents(jd_skills)\n",
    "\n",
    "    return resume_vectors, jd_vectors\n",
    "\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    dot = np.dot(vec1, vec2)\n",
    "    mag_vec1 = np.linalg.norm(vec1)\n",
    "    mag_vec2 = np.linalg.norm(vec2)\n",
    "    return dot / (mag_vec1 * mag_vec2)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example input text (later you‚Äôll load real resume/JD text)           ### I have to add extracted skills from module 1. first do this \n",
    "    resume_text = \"Resume text with Python, SQL, Machine Learning...\"\n",
    "    jd_text = \"JD requires Python, SQL, Deep Learning...\"\n",
    "\n",
    "    # üîπ Call Module 1 functions\n",
    "    resume_skills,jd_skills = extract_skills_cached(resume_text,jd_text,model_choice=\"llama3-8b-8192\")\n",
    "   \n",
    "\n",
    "    # üîπ Embed and compare\n",
    "    resume_vectors, jd_vectors = embed_skills(resume_skills, jd_skills)\n",
    "\n",
    "    for i, r_vec in enumerate(resume_vectors):\n",
    "        for j, j_vec in enumerate(jd_vectors):\n",
    "            sim = cosine_sim(r_vec, j_vec)\n",
    "            print(f\"Similarity between Resume skill '{resume_skills[i]}' and JD skill '{jd_skills[j]}': {sim:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e83a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(resume_skills, jd_skills, resume_vectors, jd_vectors, threshold=0.7):\n",
    "    matched_skills = []\n",
    "    missing_skills = []\n",
    "\n",
    "    for j, jd_skill in enumerate(jd_skills):\n",
    "        best_sim = 0\n",
    "        best_resume_skill = None\n",
    "\n",
    "        for i, resume_skill in enumerate(resume_skills):\n",
    "            sim = cosine_sim(resume_vectors[i], jd_vectors[j])\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_resume_skill = resume_skill\n",
    "\n",
    "        if best_sim >= threshold:\n",
    "            matched_skills.append((jd_skill, best_resume_skill, best_sim))\n",
    "        else:\n",
    "            missing_skills.append(jd_skill)\n",
    "\n",
    "    score = len(matched_skills) / len(jd_skills)\n",
    "    return matched_skills, missing_skills, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16a37b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed_skills' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m resume = [\u001b[33m\"\u001b[39m\u001b[33mPython\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSQL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMachine Learning\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      3\u001b[39m jd = [\u001b[33m\"\u001b[39m\u001b[33mPython\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSQL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDeep Learning\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m resume_vecs, jd_vecs = \u001b[43membed_skills\u001b[49m(resume, jd)\n\u001b[32m      6\u001b[39m matches, missing, score = find_matches(resume, jd, resume_vecs, jd_vecs)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Matches:\u001b[39m\u001b[33m\"\u001b[39m, matches)\n",
      "\u001b[31mNameError\u001b[39m: name 'embed_skills' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    resume = [\"Python\", \"SQL\", \"Machine Learning\"]\n",
    "    jd = [\"Python\", \"SQL\", \"Deep Learning\"]\n",
    "\n",
    "    resume_vecs, jd_vecs = embed_skills(resume, jd)\n",
    "    matches, missing, score = find_matches(resume, jd, resume_vecs, jd_vecs)\n",
    "\n",
    "    print(\"‚úÖ Matches:\", matches)\n",
    "    print(\"‚ùå Missing:\", missing)\n",
    "    print(\"üìä Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e5ca0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matches: []\n",
      "‚ùå Missing: []\n",
      "üìä Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(\"..\")   # one folder up from current notebook\n",
    "sys.path.append(project_root)\n",
    "from resume_skill_extractor.skill_extractor import extract_skills_cached \n",
    "from resume_skill_extractor.app import resume_text,jd_text\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Initialize Embedding model\n",
    "embeddings=(\n",
    "    OllamaEmbeddings(model=\"gemma:2b\")        ##by default it use llama2\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize embeddings\n",
    "def embed_skills(resume_skills, jd_skills):\n",
    "    \"\"\"\n",
    "    Embed each skill separately (one vector per skill).\n",
    "    \"\"\"\n",
    "    if not isinstance(resume_skills, list):\n",
    "        raise ValueError(\"resume_skills must be a list of strings\")\n",
    "    if not isinstance(jd_skills, list):\n",
    "        raise ValueError(\"jd_skills must be a list of strings\")\n",
    "\n",
    "    resume_vectors = embeddings.embed_documents(resume_skills)\n",
    "    jd_vectors = embeddings.embed_documents(jd_skills)\n",
    "\n",
    "    return resume_vectors, jd_vectors\n",
    "\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    dot = np.dot(vec1, vec2)\n",
    "    mag_vec1 = np.linalg.norm(vec1)\n",
    "    mag_vec2 = np.linalg.norm(vec2)\n",
    "    return dot / (mag_vec1 * mag_vec2)\n",
    "\n",
    "\n",
    "def find_matches(resume_skills, jd_skills, resume_vectors, jd_vectors, threshold=0.7):\n",
    "    if not jd_skills:\n",
    "        return [], [], 0.0\n",
    "    \n",
    "\n",
    "    matched_skills = []\n",
    "    missing_skills = []\n",
    "\n",
    "    for j, jd_skill in enumerate(jd_skills):\n",
    "        best_sim = 0\n",
    "        best_resume_skill = None\n",
    "\n",
    "        for i, resume_skill in enumerate(resume_skills):\n",
    "            sim = cosine_sim(resume_vectors[i], jd_vectors[j])\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_resume_skill = resume_skill\n",
    "\n",
    "        if best_sim >= threshold:\n",
    "            matched_skills.append((jd_skill, best_resume_skill, round(best_sim, 3)))\n",
    "        else:\n",
    "            missing_skills.append(jd_skill)\n",
    "\n",
    "    score = round((len(matched_skills) / len(jd_skills)) * 100, 2)\n",
    "\n",
    "    return matched_skills, missing_skills, score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Correct unpacking\n",
    "    resume_skills, jd_skills = extract_skills_cached(resume_text, jd_text, model_choice=\"mistral:latest\")\n",
    "\n",
    "    # Now this will work\n",
    "    resume_vectors, jd_vectors = embed_skills(resume_skills, jd_skills)\n",
    "    matches, missing, score = find_matches( resume_vecs,resume_vectors,jd_vectors, jd_vecs)\n",
    "\n",
    "    print(\"‚úÖ Matches:\", matches)\n",
    "\n",
    "    print(\"‚ùå Missing:\", missing)\n",
    "    print(\"üìä Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f8e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f044b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
